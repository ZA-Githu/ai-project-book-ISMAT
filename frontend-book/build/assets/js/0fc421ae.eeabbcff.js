"use strict";(globalThis.webpackChunkbook_frontend=globalThis.webpackChunkbook_frontend||[]).push([[61],{8453(e,n,i){i.d(n,{R:()=>t,x:()=>o});var a=i(6540);const s={},r=a.createContext(s);function t(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),a.createElement(r.Provider,{value:n},e.children)}},8913(e,n,i){i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>t,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"module-3-nvidia-isaac-brain/chapter-2-isaac-ros-perception","title":"Chapter 2: Isaac ROS: Accelerated Perception & VSLAM","description":"Learning Objectives","source":"@site/docs/module-3-nvidia-isaac-brain/chapter-2-isaac-ros-perception.md","sourceDirName":"module-3-nvidia-isaac-brain","slug":"/module-3-nvidia-isaac-brain/chapter-2-isaac-ros-perception","permalink":"/docs/module-3-nvidia-isaac-brain/chapter-2-isaac-ros-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-nvidia-isaac-brain/chapter-2-isaac-ros-perception.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: NVIDIA Isaac Sim & Synthetic Data","permalink":"/docs/module-3-nvidia-isaac-brain/chapter-1-nvidia-isaac-sim"},"next":{"title":"Chapter 3: Nav2 for Humanoid Navigation","permalink":"/docs/module-3-nvidia-isaac-brain/chapter-3-nav2-humanoid-navigation"}}');var s=i(4848),r=i(8453);const t={sidebar_position:3},o="Chapter 2: Isaac ROS: Accelerated Perception & VSLAM",c={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Visual SLAM Fundamentals in Isaac ROS",id:"visual-slam-fundamentals-in-isaac-ros",level:2},{value:"Core Components of VSLAM",id:"core-components-of-vslam",level:3},{value:"Isaac ROS VSLAM Architecture",id:"isaac-ros-vslam-architecture",level:3},{value:"Hardware Acceleration Concepts in Isaac ROS",id:"hardware-acceleration-concepts-in-isaac-ros",level:2},{value:"CUDA Acceleration",id:"cuda-acceleration",level:3},{value:"TensorRT Optimization",id:"tensorrt-optimization",level:3},{value:"Hardware Considerations",id:"hardware-considerations",level:3},{value:"Isaac ROS Perception Pipeline",id:"isaac-ros-perception-pipeline",level:2},{value:"Core Pipeline Components",id:"core-pipeline-components",level:3},{value:"Integration with Other ROS Systems",id:"integration-with-other-ros-systems",level:3},{value:"GPU-Accelerated Processing Techniques",id:"gpu-accelerated-processing-techniques",level:2},{value:"Parallel Processing Pipelines",id:"parallel-processing-pipelines",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Mixed-Precision Processing",id:"mixed-precision-processing",level:3},{value:"Practical Examples of Isaac ROS Packages",id:"practical-examples-of-isaac-ros-packages",level:2},{value:"Visual SLAM Implementation",id:"visual-slam-implementation",level:3},{value:"AprilTag Detection",id:"apriltag-detection",level:3},{value:"Real-World Isaac ROS Applications",id:"real-world-isaac-ros-applications",level:2},{value:"Autonomous Mobile Manipulation",id:"autonomous-mobile-manipulation",level:3},{value:"Warehouse Automation",id:"warehouse-automation",level:3},{value:"Inspection and Monitoring",id:"inspection-and-monitoring",level:3},{value:"Isaac ROS Package Integration Patterns",id:"isaac-ros-package-integration-patterns",level:2},{value:"Perception Pipeline Integration",id:"perception-pipeline-integration",level:3},{value:"Hardware Acceleration Integration",id:"hardware-acceleration-integration",level:3},{value:"Standard Integration Workflow",id:"standard-integration-workflow",level:3},{value:"Summary",id:"summary",level:2},{value:"Related Chapters",id:"related-chapters",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-2-isaac-ros-accelerated-perception--vslam",children:"Chapter 2: Isaac ROS: Accelerated Perception & VSLAM"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Understand Visual SLAM fundamentals in the context of Isaac ROS"}),"\n",(0,s.jsx)(n.li,{children:"Explain hardware acceleration concepts with Isaac ROS"}),"\n",(0,s.jsx)(n.li,{children:"Implement Isaac ROS Perception Pipeline components"}),"\n",(0,s.jsx)(n.li,{children:"Describe GPU-accelerated processing techniques for perception tasks"}),"\n",(0,s.jsx)(n.li,{children:"Apply Isaac ROS packages for Visual SLAM and Apriltag detection"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"visual-slam-fundamentals-in-isaac-ros",children:"Visual SLAM Fundamentals in Isaac ROS"}),"\n",(0,s.jsx)(n.p,{children:"Visual Simultaneous Localization and Mapping (VSLAM) is a critical capability for autonomous robots, enabling them to understand their position in an environment while simultaneously building a map of that environment using visual sensors. Isaac ROS provides optimized implementations of VSLAM algorithms that leverage NVIDIA's hardware acceleration capabilities."}),"\n",(0,s.jsx)(n.h3,{id:"core-components-of-vslam",children:"Core Components of VSLAM"}),"\n",(0,s.jsx)(n.p,{children:"Visual SLAM systems typically involve several interconnected components:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Feature Detection and Matching"}),": Identifying distinctive visual features in the environment and tracking them across consecutive frames"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Pose Estimation"}),": Computing the camera's position and orientation relative to the environment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Bundle Adjustment"}),": Optimizing 3D structure and camera poses based on observations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Loop Closure"}),": Detecting when the robot revisits previously mapped areas to correct drift"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Map Maintenance"}),": Managing the map's scale, consistency, and memory usage"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"isaac-ros-vslam-architecture",children:"Isaac ROS VSLAM Architecture"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS implements VSLAM through a collection of optimized packages that leverage CUDA and TensorRT for hardware acceleration:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS Visual SLAM (NVDSLAM)"}),": NVIDIA's deep-learning enhanced SLAM approach"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS AprilTag"}),": High-precision fiducial marker tracking"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS Stereo Dense Reconstruction"}),": 3D scene reconstruction capabilities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS ISAAC Manipulator"}),": Tools for robot manipulator tasks"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"hardware-acceleration-concepts-in-isaac-ros",children:"Hardware Acceleration Concepts in Isaac ROS"}),"\n",(0,s.jsx)(n.p,{children:"One of the key advantages of Isaac ROS is its integration with NVIDIA's GPU acceleration technologies, which significantly improves the performance of computationally intensive perception tasks."}),"\n",(0,s.jsx)(n.h3,{id:"cuda-acceleration",children:"CUDA Acceleration"}),"\n",(0,s.jsx)(n.p,{children:"CUDA enables direct utilization of NVIDIA GPU cores for general-purpose computing. Isaac ROS packages utilize CUDA kernels for:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Image processing operations"}),"\n",(0,s.jsx)(n.li,{children:"Matrix computations for pose estimation"}),"\n",(0,s.jsx)(n.li,{children:"Deep learning inference for object detection"}),"\n",(0,s.jsx)(n.li,{children:"Point cloud processing"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"tensorrt-optimization",children:"TensorRT Optimization"}),"\n",(0,s.jsx)(n.p,{children:"TensorRT is NVIDIA's inference optimizer that provides:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Model quantization for faster execution"}),"\n",(0,s.jsx)(n.li,{children:"Layer fusion to reduce memory transfers"}),"\n",(0,s.jsx)(n.li,{children:"Custom kernel optimization for specific network architectures"}),"\n",(0,s.jsx)(n.li,{children:"Dynamic batching for variable input sizes"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"hardware-considerations",children:"Hardware Considerations"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS packages are designed to work efficiently on NVIDIA Jetson platforms and discrete GPUs, taking advantage of:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Dedicated Tensor Cores for mixed-precision operations"}),"\n",(0,s.jsx)(n.li,{children:"Optimized memory hierarchy (HBM, shared memory)"}),"\n",(0,s.jsx)(n.li,{children:"High-bandwidth memory access patterns"}),"\n",(0,s.jsx)(n.li,{children:"Parallel execution of multiple perception tasks"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"isaac-ros-perception-pipeline",children:"Isaac ROS Perception Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"The Isaac ROS Perception Pipeline consists of several interconnected components that process raw sensor data and transform it into meaningful environmental understanding."}),"\n",(0,s.jsx)(n.h3,{id:"core-pipeline-components",children:"Core Pipeline Components"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Image Acquisition"}),": Capturing synchronized images from stereo cameras or multiple sensors"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Preprocessing"}),": Rectification, normalization, and format conversion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Feature Extraction"}),": Identification of visual features using accelerated algorithms"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Tracking"}),": Associating features across consecutive frames"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Optimization"}),": Bundle adjustment and pose refinement"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Trajectory, map, and intermediate processing results"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"integration-with-other-ros-systems",children:"Integration with Other ROS Systems"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS perception components integrate seamlessly with standard ROS 2 systems:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Standard sensor_msgs for image and point cloud data exchange"}),"\n",(0,s.jsx)(n.li,{children:"tf2 for coordinate transformation management"}),"\n",(0,s.jsx)(n.li,{children:"ROS 2 parameters for runtime configuration"}),"\n",(0,s.jsx)(n.li,{children:"Standard topics and services for communication"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"gpu-accelerated-processing-techniques",children:"GPU-Accelerated Processing Techniques"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS employs several techniques to maximize GPU utilization for perception tasks:"}),"\n",(0,s.jsx)(n.h3,{id:"parallel-processing-pipelines",children:"Parallel Processing Pipelines"}),"\n",(0,s.jsx)(n.p,{children:"Different stages of perception can run in parallel:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"While one frame is being processed by the SLAM algorithm, another can be undergoing deep learning inference"}),"\n",(0,s.jsx)(n.li,{children:"Multiple cameras or sensors can share the same GPU resources through proper scheduling"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,s.jsx)(n.p,{children:"Efficient GPU memory management is critical:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pinned host memory for faster GPU transfers"}),"\n",(0,s.jsx)(n.li,{children:"Memory pooling to reduce allocation overhead"}),"\n",(0,s.jsx)(n.li,{children:"Zero-copy memory sharing between CUDA kernels and OpenGL contexts"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"mixed-precision-processing",children:"Mixed-Precision Processing"}),"\n",(0,s.jsx)(n.p,{children:"Tensor Cores enable significant speedups through mixed-precision computation:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Maintaining accuracy for critical operations in FP32"}),"\n",(0,s.jsx)(n.li,{children:"Accelerating matrix operations in FP16 or INT8"}),"\n",(0,s.jsx)(n.li,{children:"Careful numerical analysis to ensure stability"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"practical-examples-of-isaac-ros-packages",children:"Practical Examples of Isaac ROS Packages"}),"\n",(0,s.jsx)(n.h3,{id:"visual-slam-implementation",children:"Visual SLAM Implementation"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS Visual SLAM package combines traditional geometric methods with deep learning enhancement:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# Example configuration for NVDSLAM\nnvds_slam_node:\n  ros__parameters:\n    camera_type: "stereo"\n    image_width: 1920\n    image_height: 1080\n    gpu_id: 0\n    enable_rectification: true\n    publish_pose_graph: true\n    enable_localization: true\n'})}),"\n",(0,s.jsx)(n.h3,{id:"apriltag-detection",children:"AprilTag Detection"}),"\n",(0,s.jsx)(n.p,{children:"AprilTag detection provides high-precision fiducial marker tracking:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'#include "isaac_ros_apriltag_interfaces/msg/april_tag_detection_array.hpp"\n\n// Isaac ROS AprilTag node automatically detects and tracks AprilTag markers\n// with millimeter-level pose accuracy\n'})}),"\n",(0,s.jsx)(n.h2,{id:"real-world-isaac-ros-applications",children:"Real-World Isaac ROS Applications"}),"\n",(0,s.jsx)(n.h3,{id:"autonomous-mobile-manipulation",children:"Autonomous Mobile Manipulation"}),"\n",(0,s.jsx)(n.p,{children:"In a typical mobile manipulation scenario using Isaac ROS packages:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Perception Pipeline"}),": RGB-D sensors feed into Isaac ROS stereo dense reconstruction"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"SLAM Integration"}),": Visual SLAM maintains a consistent map of the environment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Object Detection"}),": Isaac ROS detection networks identify objects of interest"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Planning"}),": Navigation and manipulation planners use the processed information"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Execution"}),": Commands are sent to robot controllers with closed-loop feedback"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"warehouse-automation",children:"Warehouse Automation"}),"\n",(0,s.jsx)(n.p,{children:"For warehouse robot applications:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scene Understanding"}),": Isaac ROS segmentation networks identify obstacles and pathways"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Localization"}),": VSLAM maintains precise robot positioning relative to warehouse map"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fiducial Tracking"}),": AprilTag detection allows precise alignment with inventory stations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Path Planning"}),": Nav2 integration provides collision-free navigation to waypoints"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Grasping"}),": Isaac ROS manipulation packages enable precise object pickup and placement"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"inspection-and-monitoring",children:"Inspection and Monitoring"}),"\n",(0,s.jsx)(n.p,{children:"For robotic inspection tasks:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sensor Fusion"}),": Isaac ROS packages combine data from multiple sensor types"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Defect Detection"}),": Deep learning models running on GPU identify anomalies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Trajectory Optimization"}),": Predefined paths ensure complete coverage of inspection zones"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Capture"}),": High-resolution imagery is processed and stored for review"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Reporting"}),": Automated reports highlight detected issues with precise location data"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"isaac-ros-package-integration-patterns",children:"Isaac ROS Package Integration Patterns"}),"\n",(0,s.jsx)(n.h3,{id:"perception-pipeline-integration",children:"Perception Pipeline Integration"}),"\n",(0,s.jsx)(n.mermaid,{value:"graph LR\n    A[Stereo Cameras] --\x3e B{Isaac ROS Stereo Rectification}\n    B --\x3e C{Isaac ROS Visual SLAM}\n    C --\x3e D{Isaac ROS Obstacle Detection}\n    D --\x3e E[Navigation Planner]\n    F[LiDAR] --\x3e G{Isaac ROS LiDAR Processing}\n    G --\x3e D"}),"\n",(0,s.jsx)(n.h3,{id:"hardware-acceleration-integration",children:"Hardware Acceleration Integration"}),"\n",(0,s.jsx)(n.p,{children:"The following packages provide hardware acceleration for different perception tasks:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS Visual SLAM"}),": Accelerates pose estimation and mapping using GPU"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS Stereo Dense Reconstruction"}),": Accelerates 3D reconstruction using CUDA cores"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS Detection NITROS"}),": Accelerates object detection using TensorRT"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS AprilTag"}),": Accelerates fiducial marker detection and pose estimation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS Image Pipeline"}),": Accelerates preprocessing operations using GPU"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"standard-integration-workflow",children:"Standard Integration Workflow"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Launch Configuration"}),": Configure Isaac ROS nodes with appropriate parameters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Resource Allocation"}),": Assign GPU resources to perception nodes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Flow Verification"}),": Verify sensor data flows through pipeline correctly"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance Tuning"}),": Optimize parameters for target frame rates"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Integration Testing"}),": Validate complete pipeline with robot system"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS provides a comprehensive suite of hardware-accelerated perception tools that enable efficient and high-performance visual SLAM implementations. Through CUDA and TensorRT optimization, these packages deliver real-time performance for demanding perception tasks on NVIDIA hardware platforms, making them ideal for humanoid robot applications where processing efficiency is paramount."}),"\n",(0,s.jsx)(n.p,{children:"The standardized ROS 2 interfaces ensure that Isaac ROS perception components can be easily integrated with other ROS packages and custom applications, providing flexibility while maintaining high performance."}),"\n",(0,s.jsx)(n.h2,{id:"related-chapters",children:"Related Chapters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/docs/module-3-nvidia-isaac-brain/chapter-1-nvidia-isaac-sim",children:"Chapter 1: NVIDIA Isaac Sim & Synthetic Data"})," - Learn about simulation and synthetic data generation foundations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/docs/module-3-nvidia-isaac-brain/chapter-3-nav2-humanoid-navigation",children:"Chapter 3: Nav2 for Humanoid Navigation"})," - Explore navigation concepts for humanoid robots"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);